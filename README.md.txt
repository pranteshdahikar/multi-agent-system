ğŸ§  Multi-Agent Repository Analyzer
ğŸš€ Production-Ready AI System | Module 3 â€“ Agentic AI Developer Capstone

A production-grade multi-agent system that analyzes GitHub repositories â€” summarizing their structure, extracting metadata, and suggesting improvements.
This project extends the prototype from Module 2: Build a Multi-Agent System into a robust, tested, and user-ready AI application.

ğŸŒŸ Project Overview

The Multi-Agent Repository Analyzer automates code understanding and review.
It uses a team of specialized AI agents to analyze a repository, extract metadata, and provide actionable improvement suggestions.

You can interact with it via a Streamlit web interface or directly through Python functions.

ğŸ—ï¸ System Architecture
ğŸ”¹ Agents
Agent	Purpose
AnalyzerAgent	Summarizes repository content and identifies structure & documentation gaps.
MetadataAgent	Extracts structured metadata (project name, tech stack, author, license, etc.).
ImproverAgent	Suggests improvements for code quality, documentation, and structure.
ğŸ”¹ Tools
Tool	Function
repo_reader	Reads and summarizes repository files (README, .py, .md, etc.)
web_search_tool	Performs web lookups using DuckDuckGo (optional for enrichment)
summarizer	Combines multi-agent outputs into a cohesive summary
guardrails	Validates inputs, filters outputs, and enforces safety rules
ğŸ”¹ Workflow
RepoReader â†’ AnalyzerAgent â†’ MetadataAgent â†’ ImproverAgent â†’ Summarizer


Each agent operates independently but contributes to the shared analysis context.

ğŸ§© Key Features

âœ… Modular Multi-Agent System â€“ Each agent handles a unique task
âœ… LLM Integration â€“ Uses langchain_openai.ChatOpenAI or a fallback DummyLLM
âœ… Comprehensive Testing Suite â€“ Unit + Integration + End-to-End tests
âœ… Safety & Guardrails â€“ Input validation, output filtering, and error handling
âœ… Interactive Streamlit UI â€“ Simple user interface for non-technical users
âœ… Resilience â€“ Graceful fallback when API or network calls fail
âœ… Documentation & Maintainability â€“ Clear module structure and inline comments

ğŸ§° Project Structure
multi-agent-system/
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ analyzer_agent.py
â”‚   â”œâ”€â”€ improver_agent.py
â”‚   â”œâ”€â”€ metadata_agent.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ repo_reader.py
â”‚   â”œâ”€â”€ summarizer.py
â”‚   â”œâ”€â”€ web_search_tool.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ guardrails.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_analyzer_agent.py
â”‚   â”œâ”€â”€ test_metadata_agent.py
â”‚   â”œâ”€â”€ test_improver_agent.py
â”‚   â”œâ”€â”€ test_end_to_end.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ app.py                  # Streamlit UI
â”‚
â”œâ”€â”€ your_dummy_llm.py           # Mock LLM for tests
â”œâ”€â”€ main.py                     # Workflow orchestrator
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md                   # (This file)

âš™ï¸ Installation
1ï¸âƒ£ Clone Repository
git clone https://github.com/yourusername/multi-agent-system.git
cd multi-agent-system

2ï¸âƒ£ Create Virtual Environment
python -m venv venv
source venv/bin/activate     # Mac/Linux
venv\Scripts\activate        # Windows

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt


If langchain_openai or langchain_community are missing, install manually:

pip install langchain-openai langchain-community streamlit duckduckgo-search

ğŸ§ª Running Tests
Run all tests:
pytest -v

Expected Output:

âœ… 3 passed, 1 skipped or passed depending on test environment
âœ… 70%+ coverage on agents and tools

ğŸ’» Running the Application
Start the Streamlit UI
streamlit run ui/app.py


Then open your browser at:

http://localhost:8501

Example Usage

Enter a local repository path

Click â€œAnalyze Repositoryâ€

View structured JSON output:

{
  "analysis": "...",
  "metadata": {...},
  "improvements": "..."
}

ğŸ§  Safety & Guardrails

Implemented via utils/guardrails.py:

Input validation â€” rejects empty/malformed input

Output filtering â€” removes sensitive or unsafe content

Error handling â€” catches LLM or file read errors gracefully

Fallback LLM â€” uses DummyLLM if API unavailable

ğŸ” Resilience & Monitoring

Retry & fallback mechanisms for failed LLM or I/O operations

Safe defaults for repository scanning

Logging of critical errors and exceptions (to be extended with monitoring tools)

ğŸ¨ User Interface (Streamlit)
Feature	Description
Input field	Enter local repo path
â€œAnalyze Repositoryâ€	Triggers multi-agent workflow
JSON Viewer	Displays final output (analysis, metadata, improvements)
Error Handling	Shows descriptive error messages
ğŸ§¾ Example Output
{
  "analysis": "This repository implements a Python-based web service using FastAPI...",
  "metadata": {
    "project_name": "FastAPI Boilerplate",
    "technologies": ["Python", "FastAPI", "Docker"],
    "author": "John Doe",
    "license": "MIT"
  },
  "improvements": "Add test coverage, update documentation, follow PEP8."
}

ğŸ§© Deployment Notes

For deployment on a server or container:

pip install gunicorn
gunicorn ui.app:app


Optional enhancements:

Dockerize with Dockerfile

Add logging & monitoring (Sentry / OpenTelemetry)

Integrate with CI/CD pipeline for test automation

ğŸ“˜ Troubleshooting
Issue	Possible Fix
streamlit: command not found	Run pip install streamlit
ModuleNotFoundError: langchain_openai	Run pip install langchain-openai
Tests failing due to LLM	Use DummyLLM for offline mode
Repository not found	Ensure valid local repo path or absolute directory
ğŸ Learning Outcomes

By completing this project, you demonstrate:

Building & testing multi-agent AI systems

Implementing guardrails & safe execution flows

Creating user interfaces for AI tools

Achieving production-grade reliability

ğŸ§‘â€ğŸ’» Author

Prantesh Dahikar
AI & Automation Engineer | Capstone Project for Agentic AI Developer Certification

ğŸ§© License

MIT License Â© 2025 â€“ Multi-Agent Repository Analyzer